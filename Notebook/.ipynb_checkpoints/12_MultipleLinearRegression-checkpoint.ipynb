{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c589f8e1-2430-45ea-bef9-e881fb96f5c0",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "It is used to assess relationship between two variables while taking into account the effect of other variables. By taking into account the effect of other variables, we cancel out the effect of these other variables in order to isolate and measure the relationship between the two variables of interest. \n",
    "\n",
    "Is an extension of *simple linear regression* in case dependent variable $Y$ is related to more than one independent variable $X$.\n",
    "\n",
    "The regression equation become:\n",
    "\n",
    "$$Y=b\\beta_0 + b\\beta_1 x_1 + b\\beta_2 x_2 + ... + b\\beta_p x_p + \\epsilon$$\n",
    "\n",
    "where $E(\\epsilon)=0$ and $Var(\\epsilon)=\\sigma^2$ (normal distribution)\n",
    "\n",
    "\n",
    "We can split the problem in two:\n",
    "1. Assessing fucntional relationship between a dependent variable and multiple independent variables\n",
    "2. Assessing functional relationship between several dependent variable and multiple independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0393c15-8edd-493a-8dd6-5ad8571452e8",
   "metadata": {},
   "source": [
    "### 1. Multiple Linar Regression - Problem 1\n",
    "\n",
    "Firstly we test the relation and significance of each individual variable and if there is no significance the variable can be removed.\n",
    "then we rerun the model fitting until only significant independent varaibles remain. (backward elimination)\n",
    "\n",
    "Let's __chose__ which relationship between dependent and independent variable we want to analyse an let's take into account also other factors that can affect this relationship.\n",
    "\n",
    "e.g. Analyse how the car's fuel consumption `mpg` is affected by the car weigth `wt` but also considering the number of cylinders, the transmission type `am` and the number of carburators `carb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973328c-5401-4cf5-9438-f2a1129f4218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets plot firstly the  scatter plot between mpg and wt\n",
    "library(ggplot2)\n",
    "data= mtcars\n",
    "ggplot(data) +\n",
    "  aes(x = wt, y = mpg, colour = carb, size = cyl) +\n",
    "  geom_point() +\n",
    "  scale_color_gradient() +\n",
    "  labs(\n",
    "    y = \"Miles per gallon\",\n",
    "    x = \"Weight (1000 lbs)\",\n",
    "    color = \"Number of carburetors\",\n",
    "    size = \"Number of cylinders\"\n",
    "  ) +\n",
    "  theme_minimal()\n",
    "\n",
    "\n",
    "pearson_cor_coef = cor(data$wt,data$mpg)\n",
    "list(\"cor\"=pearson_cor_coef,\"R^2\"=pearson_cor_coef^2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26116c5-5d56-408f-953f-c45fe999fbd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can observe:\n",
    "- a strong and negative  relationship between miles per gallon and weight\n",
    "- a negative relationship between miles/gallon and number of cylinders\n",
    "- a negative relationship between miles/gallon and number of carburetors\n",
    "\n",
    "\n",
    "From this first graphical observation, lets firstly consider the __Simple Linear Regression__ between the independent variable `wt` and the dependent variable `mpg`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8e85e-2361-4474-97b6-ee0112261549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simplelr <-lm(formula=mpg ~ wt, data)\n",
    "summary(simplelr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8ec9ab-de72-4713-80dc-5ee1940ec640",
   "metadata": {},
   "source": [
    "How well does the linear regression model fit the data? Observing the residuals we see that they are pretty symmetrical around median zero. \n",
    "The slope is negative and the $R^2$ is quite high indicating a pretty strong negative correlation. For each increas of `wt` of 1 unit the `mpg` decreas by 5.34\n",
    "\n",
    "Testing this correlation for significance means to observe the p-value. for both intercept and slope the p-value is lower than the significance level of 0.05 which means that the null-hypotesis is rejected. Therefore we consider valid the alternative hypotesis which state that there is a linear regression model that well fit our data and could be valid for the entire population.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadae2a3-a2ef-43a3-b9ae-2b80052b5fa3",
   "metadata": {},
   "source": [
    "Therefore, we would like to evaluate the relation between the fuel consumption and the weight, but this time by adding `cyl`, `am` and `carb`. Let's apply __Multiple Linear Regression__: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dbd58c-02a4-44ce-b80e-96448d76ef22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's fit to a linear regression model:\n",
    "data= mtcars\n",
    "multilr <-lm(formula=mpg ~ wt + cyl + am + carb, data)\n",
    "summary(multilr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa0e9da-493a-4c6b-b283-589e2f3e07b5",
   "metadata": {},
   "source": [
    "Observing the slope of `wt` we observe a weaker relationship this time with respect to the previous simple linear regression (-5.34 vs -2.37). In this results, the effect of `wt` on `mpg` was adjusted according to the effect of `cyl`, `am` and `carb`.\n",
    "\n",
    "\n",
    "\n",
    "In this table of parameter estimates, we see the number of cylinders `cyl` and weight `wt` provide a great amount of explanatory value in describing `mpg` values. The number of carburetors `carb` has limited value, and the transmission type (`am`: automatic or manual) makes a minimal contribution. The estimated coefficients for cylinders and weight are negative because, intuitively, larger engines and heavier cars will get fewer miles per gallon.\n",
    "\n",
    "__in summary__  using `am` does not provide benefit to the model and `carb` provide just minimal contribution. We can chose to fit the model for mpg on just `wt` and `cyl`.\n",
    "\n",
    "\n",
    "The regression model with fitted parameter values is:\n",
    "\n",
    "$$mpg = 36.85 − 1.20 cyl − 2.48 wt + 1.78 am − 0.75 carb + error$$ \n",
    "\n",
    "\n",
    "we can use this regression model to give a reasonable estimate of avarage miles per gallon of a car from a set of parameters between the ranges -> __Prediction__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde82e59-f784-4bee-adf2-991623f82ce3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercize:</b> Perform linear regression analysis on the previous dataset removing the non significant variables and perform a comparison with the previous model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607550ea-8419-4864-8e0f-8979b90f1903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e3307d6-328f-4eca-833f-ded37e5331cc",
   "metadata": {},
   "source": [
    "### Assessing the validity of linear regression model\n",
    "Diagnostic plots for the model can reveal whether or not modelling assumptions are reasonable.\n",
    "\n",
    "As for simple linear regression, multiple linear regression requires some conditions of application for the model to be usable and the results to be interpretable. These are:\n",
    "\n",
    "1. Linearity of the relationships between the dependent and independent variables\n",
    "2. Independence of the observations\n",
    "3. Normality of the residuals\n",
    "4. Homoscedasticity of the residuals\n",
    "5. No influential points (outliers)\n",
    "6. No multicollinearity (Multicollinearity arises when there is a strong linear correlation between the independent variables, conditional on the other variables in the model. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2e8e7-0e72-48b6-9c14-fceb6b674c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot(multilr, which=1:6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47db008-f78a-43ef-9483-274e384275dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. linearity (Residulas vs fitted) is not perfect—a variable could be removed/added or a transformation could be applied to improve linearity\n",
    "2. acqusition dependent\n",
    "3. Normality of the residuals (QQ plots) is also not perfect but it still seems acceptable\n",
    "4. Homogeneity of variance (Scale-location) is almost respected\n",
    "5. There is no influential points (Resiuals vs Leverage). Point should be inside the contour lines.\n",
    "6. perform VIF\n",
    "\n",
    "When the conditions of application are met, the model is valid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddeeb75-10a1-44bf-8ce7-fc622959c81c",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "\n",
    "Suppose we want to predict the miles/gallon for a car with a manual transmission, weighting 3000 lbs, has 8 cylinders, 4 carburetors and which drives a quarter of a mile (qsec) in 18 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b14ecf-6aa3-4948-84c5-2346d21d0b50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# confidence interval for new data\n",
    "predict(multilr,\n",
    "  new = data.frame(cyl = 8, wt = 3, carb= 4, qsec = 18, am = 1),\n",
    "  interval = \"confidence\",\n",
    "  level = .95\n",
    ")\n",
    "\n",
    "# prediction interval for new data\n",
    "predict(multilr,\n",
    "  new = data.frame(cyl = 8, wt = 3, carb= 4, qsec = 18, am = 1),\n",
    "  interval = \"prediction\",\n",
    "  level = .95\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a8983-a15a-42ff-9166-18fbb99cc0d7",
   "metadata": {},
   "source": [
    "The difference between the confidence and prediction interval is that:\n",
    "\n",
    "- a confidence interval gives the predicted value for the mean of Y  for a new observation, whereas\n",
    "- a prediction interval gives the predicted value for an individual Y  for a new observation.\n",
    "\n",
    "Based on our model, it is expected that this car will drive 18.62 miles with a gallon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccc3d47-9284-4c6d-bdab-94cd6ae7089a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercize:</b> Perform linear regression analysis on the previous dataset using generalize linear model (glm() and aov()).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113218da-9981-4650-bc14-643999c08359",
   "metadata": {},
   "source": [
    "### 2. Multiple Linear Regression - Problem 2\n",
    "\n",
    "Another approach to perform multiple linear regression is the following:\n",
    "\n",
    "- First, we perform separate, univariate linear regressions for each of the dependent variables $y$ and capture the residuals for each of these regressions. Each separate regression provides the estimated regression coeﬃcients, regardless of how the various dependent variables are correlated with each other.\n",
    "\n",
    "- The second step is to perform a principal components or factor analysis on the residuals to see if there is additional information in the dependent variables, after having corrected for the eﬀects of the explanatory $x$ variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3998227c-0929-4b17-bb06-279cf536f61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multilr.mpg <- aov(mpg ~ cyl + disp + am + carb , data = mtcars)\n",
    "summary(multilr.mpg)\n",
    "multilr.hp <- aov( hp ~ cyl + drat + am + gear + carb, data = mtcars)\n",
    "summary(multilr.hp)\n",
    "multilr.wt <- aov( wt ~ cyl + disp + drat + am + carb, data = mtcars)\n",
    "summary(multilr.wt)\n",
    "multilr.qsec <- aov( qsec ~ cyl + disp + drat + vs + am + gear, data = mtcars)\n",
    "summary(multilr.qsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5136ac-dee5-40fc-b0d9-baf9c25af39a",
   "metadata": {},
   "source": [
    "### 2.1 Anlayse the residuals\n",
    "We obtain 4 fitted models. The residuals from the four separate regressions can be captured and combined into a single data.frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c04637-18ac-464e-92c0-2454bbdab4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "car.res <- cbind( multilr.mpg$residuals, multilr.hp$residuals,\n",
    "+ multilr.wt$residuals, multilr.qsec$residuals)\n",
    "\n",
    "colnames(car.res)<- c(\"mpg_res\", \"hp_res\", \"wt_res\", \"qsec_res\")\n",
    "car.res <- data.frame(car.res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3ff6ad-c58c-4381-893d-55c49b9143af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(car.res, digits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29498e9-a10a-480c-b9f4-3cadbb3b4b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#windows()\n",
    "layout(matrix(1:4, nrow=2, byrow=T))\n",
    "plot(multilr.mpg, which=1) \n",
    "plot(multilr.hp, which=1) \n",
    "plot(multilr.wt, which=1) \n",
    "plot(multilr.qsec, which=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f02f13-de68-4422-b491-8003206d4aa2",
   "metadata": {},
   "source": [
    "Observe the car's models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0caaae-4107-4b6a-b7d2-b1d00b6d1788",
   "metadata": {},
   "source": [
    "A multivariate examination of these residuals begins with the matrix scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3952f-fe14-44f6-aaab-6d7dcc06e562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(psych)\n",
    "pairs.panels(car.res, scale=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c596b26-53d9-4759-a3f2-1f170139dc9e",
   "metadata": {},
   "source": [
    "We observe that there is no strong correlation between residuals. (see the 0.52 as maximum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e5d0d-c710-4937-8b41-d53bcbc0f94e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's plot the [QQ plot](#QQ) if the Mahalanobis distances for the four-dimesional residuals and lets observe the outliers. We can omit the single observation with the largest Mahalnobis distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7ead9-a8a8-41e3-9fd6-fb25eda89c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mah<-mahalanobis(car.res, colMeans(car.res), var(car.res))\n",
    "\n",
    "outliers= boxplot.stats(mah)$out\n",
    "outlier_names = rownames(car.res)[which(mah %in% outliers)]\n",
    "print(outlier_names)\n",
    "# Plot the Q-Q plot of the Mahalanobis distances with respect to the 4-degree-of-freedom chi-squared quantile\n",
    "qqplot(qchisq(p = ppoints(length(mah)), df = 4),mah, main = \"Q-Q Plot of Mahalanobis Distances with Respect to 4df Chi-Squared Quantile\",xlab = \"Chi-Squared quantile\", ylab =\"Mahalanobis distances from the sample mean\")\n",
    "abline(a = 0, b = 1, col = \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d182a-8008-4e10-8799-41820b46beab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(mah)\n",
    "# Identify the outliers\n",
    "outliers <- boxplot.stats(mah)$out\n",
    "outliers\n",
    "\n",
    "outlier_names <- rownames(mtcars)[mah %in% outliers]\n",
    "\n",
    "library(mvnormtest)\n",
    "mshapiro.test( t( car.res))\n",
    "\n",
    "outi <- match(max(mah),mah) # index of outlier\n",
    "mshapiro.test( t( car.res[-outi,] ))\n",
    "\n",
    "mah2 <- mahalanobis(car.res[-outi,], colMeans(car.res[-outi,]), var(car.res[-outi,]))\n",
    "qqnorm(mah2)\n",
    "qqline(mah2, col = \"red\")\n",
    "\n",
    "\n",
    "# Plot the Q-Q plot of the Mahalanobis distances with respect to the 4-degree-of-freedom chi-squared quantile\n",
    "qqplot(qchisq(p = ppoints(length(mah2)), df = 4),mah2, main = \"Q-Q Plot of Mahalanobis Distances with Respect to 4df Chi-Squared Quantile\",xlab = \"Chi-Squared quantile\", ylab =\"Mahalanobis distances from the sample mean\")\n",
    "abline(a = 0, b = 1, col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989490b4-104e-459b-aa14-50d62099220d",
   "metadata": {
    "tags": []
   },
   "source": [
    "The ﬁt to a multivariate normal distribution improves slightly, but is still suspect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7019d7-a414-46a6-a0fa-f19554aeb3a9",
   "metadata": {},
   "source": [
    "### 2.2 Principal component analysis (R-mode)\n",
    "\n",
    "The next step in this multivariable linear regression is to perform a principal components analysis [PCA](#PCA) on these residuals. The object of this examination\n",
    "is to see if there is any additional information remaining between the four\n",
    "dependent variables (mpg, hp, wt, qsec) after accounting the linear effects\n",
    "of the explanatory variables (cyl, disp, drat, vs, am, gear, carb).\n",
    "The principal components analysis in R is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed102e81-2e2d-4ba3-8ff3-4df12ade2fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(prcomp(car.res, scale = TRUE), digits = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41deda72-887e-4a73-99ae-9d2947eb33ec",
   "metadata": {},
   "source": [
    "We observe that PC1 increase when mpg_res and hp_res are incresed and it is positively correlated. On the other hand, PC1 increase wehn wt_res and qse_res decrease.\n",
    "\n",
    "A good visualization is given by the `biplot`.\n",
    "\n",
    "In the list of ordered standard deviations, we see all four principal components are comparable in magnitude; the largest is just slightly twice the size of the smallest. We interpret the loadings here to mean that the residuals\n",
    "of hp, wt,and qsec are all highly correlated with each. The mpg residuals are independent of these three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a38b11-f644-48db-8bf4-52f40956b2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pc <- prcomp(car.res, scale = TRUE)\n",
    "biplot(pc, col = c(2, 3), cex = c(.75, 1.5),\n",
    "xlim = c( -.45, .45),\n",
    "xlab = \"First principal component\",\n",
    "ylab = \"Second principal component\",\n",
    "main = \"Biplot for cars\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d760dd7c-c38c-4e85-b03b-c6d8ed99a7f8",
   "metadata": {},
   "source": [
    "### 2.3. Stepwise Linar Regression\n",
    "Stepwise regression automates the model-building process. We start with a linear model containing all of the explanatory variables and removes one at a time. \n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercize:</b> Perform backward stepwise regression. Does the ﬁnal ﬁtted model from this program coincide with our intuition?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8326a866-d16a-46bd-8927-1a4b92d72e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "backward <- stepAIC(multilr)\n",
    "summary(backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06764022-4f2a-4057-b891-58862b3ede02",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Linear Discriminant analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f638c-2a54-4a9e-acc9-fbc733d4f8f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "In discriminant analysis we try to identify linear combinations of several variables that can be used to distinguish between the groups. \n",
    "Discriminant Analysis (DA) is a statistical technique used to identify the relationship between one or more independent variables and a categorical dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a07129-9fcb-4d1d-920d-5051f3b60356",
   "metadata": {},
   "source": [
    "Let's apply linear discriminant analysis on mtcars dataset. In particular let's use as categorical dependen variable the number of cylinders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1166947f-c4c5-4252-905d-5b2ddec5c09a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "# we use the lda() function\n",
    "lda1 <- lda(cyl ~ mpg + hp + qsec + drat + disp, data = mtcars)\n",
    "summary(lda1)\n",
    "\n",
    "Class=unclass(as.factor(mtcars$cyl))\n",
    "pairs(mtcars[c(\"mpg\", \"hp\", \"qsec\", \"drat\", \"disp\")], pch = 21, cex=2, bg = c(\"red\", \"blue\", \"green\")[unclass(as.factor(mtcars$cyl))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9becc-76ab-40a7-98e2-16beb37b1df5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading <- as.matrix(mtcars[c(\"mpg\", \"hp\", \"qsec\", \"drat\", \"disp\")]) %*% lda1$scaling\n",
    "plot(loading, col = c(\"red\", \"blue\", \"green\")[unclass(as.factor(mtcars$cyl))],\n",
    "pch = 16, cex = 1.25,\n",
    "xlab = \"First linear discriminator\",\n",
    "ylab = \"Second linear discriminator\")\n",
    "for(i in 1:3) #addclass number to each centroid\n",
    "{\n",
    "    centx <- mean(loading[unclass(as.factor(mtcars$cyl)) == i,][,1])\n",
    "    centy <- mean(loading[unclass(as.factor(mtcars$cyl)) == i,][,2])\n",
    "    text(centx, centy, i, cex = 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc310eb-af8e-471e-9905-c25b55f1d1e1",
   "metadata": {},
   "source": [
    "We can observe a clear distinction between the three cylinders cars.\n",
    "\n",
    "The fitted (posterior) estimated probabilities of group membership can be obtained as predict(ld)$posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326220e-db56-409b-8f31-13543341abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred <- predict(lda1)\n",
    "summary(pred)\n",
    "ldahist(data = pred$x[,1], g=mtcars$cyl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21267f4-f7bd-4d49-a992-abf1ba06bc1c",
   "metadata": {},
   "source": [
    "<a id='QQ'></a>\n",
    "\n",
    "\n",
    "A simple graphical method for checking normality is the quantile–quantile plot or QQ plot.This plot compares the quantiles of the observed values with those of the theoretical distribution, hence the name QQ. The QQ plot displays the sorted, observed values against the values that we would expect to observe had they been sampled from a theoretical normal distribution. If the observed data was sampled from a normal distribution, then we would expect these values to form a nearly straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8544741b-bf24-4695-81d2-e6fa4dc9429a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='PCA'></a>\n",
    "\n",
    "PCA is a multivariate technique commonly used for dimensionality __reduction__ by using each data point onto only the first few principal components (most cases first and second dimensions) to obtain lower-dimensional data while keeping as much of the data’s variation as possible.\n",
    "PCA identifies variables that are higly correlated with each other and combine these to construct a reduced set of new variables that still describes differences among samples.\n",
    "\n",
    "The first principal component can equivalently be defined as a direction that maximizes the variance of the projected data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
