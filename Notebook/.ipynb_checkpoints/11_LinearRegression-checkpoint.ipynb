{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e84e25-c9ed-466b-a41a-6e64b2be514a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Relationship between variables: \n",
    "## <i>Linear Correlation and Linear Regrassion </i>\n",
    "\n",
    "For each sampling or experimental teast we have two or more observations/measures (variables). If two variable are __related__, they vary togheter.\n",
    "If two variables are __funcionally related__, they vary togheter and the value of one variable can be __predicted__ from the value of the other variable.\n",
    "\n",
    "This relationship can be observed by the analysis of the pattern between the bivariate data (ScatterPlot).\n",
    "\n",
    "It is sufficient to affirms that the two variable of the population are related? \n",
    " NO! It could be an apparent relationship occurred by chance. We need *statistical procedures.*\n",
    "\n",
    "A statistical test will provide:\n",
    "- the strength of the relationship;\n",
    "- the probability of the result\n",
    "\n",
    "Two methods (quantitative data): \n",
    "- linear correlation (relationship)\n",
    "- linear regression (functional relationship)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a26777-91c0-4355-a0cf-f760ad611df1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Linear correlation\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/34/Correlation_coefficient.png\" width=\"300\">\n",
    "\n",
    "\n",
    "__Pearson correlation coefficient__\n",
    "\n",
    "Firstly we need to tranform bivariate data measured on different scales to their Z score (mean = 0 and std= 1)\n",
    "formula: \n",
    "$$Z=\\frac{{X_1}-\\bar{X}}{s}$$\n",
    "\n",
    "The __pearson correlation__ $r$ formulas:\n",
    "\n",
    "$$r = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$$\n",
    "\n",
    "Where $r$ is the Pearson correlation coefficient, $x_i$ and $y_i$ are the values of the two variables at observation $i$, $n$ is the number of observations, and $\\bar{x}$ and $\\bar{y}$ are the means of the variables $x$\n",
    "\n",
    "\n",
    "The __coefficient of determination__ $R^2$:\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$$\n",
    "\n",
    "Where $n$ is the number of observations, $y_i$ are the observed values, $\\hat{y_i}$ are the predicted values, and $\\bar{y}$ is the mean of the observed values.\n",
    "\n",
    "$R^2$ is a statistic that shows the proportion of the total variation of the values of $Y$ from the avarage $\\bar{Y}$ that is explained by the regression line.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102738b-3ad4-4808-b51f-17790043075e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting y against x, you'll observe a positive linear relationship:\n",
    "x = runif(50,0,50)\n",
    "y = x + rnorm(50,0,5)\n",
    "plot(y~x)\n",
    "pearson_cor_coef = cor(x,y)\n",
    "list(\"cor\"=pearson_cor_coef,\"R^2\"=pearson_cor_coef^2)\n",
    "text(0, 50, \"r strong and positive,\n",
    "R^2 strong and positive\", pos = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7323aad3-918e-458a-8348-fd6a072bc229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = -x + rnorm(50,0,5)\n",
    "plot(y~x)\n",
    "pearson_cor_coef = cor(x,y)\n",
    "list(\"cor\"=pearson_cor_coef,\"R^2\"=pearson_cor_coef^2)\n",
    "text(30, 0, \"r strong and negative,\n",
    "R^2 strong and positive\", pos = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87743d-e176-4c86-ae0e-a242d7e3e8bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = rnorm(50,0,5)\n",
    "plot(y~x)\n",
    "pearson_cor_coef = cor(x,y)\n",
    "list(\"cor\"=pearson_cor_coef,\"R^2\"=pearson_cor_coef^2)\n",
    "text(0, 10, \"r and R^2 ~ zero\", pos = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bda822c-77b8-4eeb-a8d7-ba95f310e529",
   "metadata": {
    "tags": []
   },
   "source": [
    "The linear relationship identified between two variables describing the observed sample is valid also in the population? The significance of a correlation can be tested using `cor.test()`, which also provides a 95% confidence interval on the correlation. It use the t-test and in general it is tested whether the correlation coefficient deviates significantly different from zero. The *null-hypotesis* is $\\rho=0$ (There is NO Linear relationship) which means that the non-linearity of the correlation is significant, the *alternative hypotesis* is $\\rho \\neq 0$ (There is Linear relationship) which means that the linearity of the correlation is significant.\n",
    "\n",
    "1. check if the null-hypotesis is retained or rejcted.\n",
    "\n",
    "Let's test the significance of the correlation (last case):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b4212-7dfa-48b4-8f87-8d0ed78c9c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cor.test(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118c0b1-112c-40ac-ab22-0995724e26d1",
   "metadata": {},
   "source": [
    "The p-value is larger than the significance level of 0.05. In this case the null-hypotesis is retained therefore there is no correlation in the population based in the sample.  In this case, the value 0 is contained within the confidence interval, indicating that there is insufficient evidence to reject the null hypothesis ($\\rho=0$). Overall p-value is high!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad4a278-f24c-4a40-b1ef-f1adb91789ac",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercize:</b> Perform cor.test also for the previous cases (r \"strong and positive\".)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf18fe-5a52-4e22-baf8-6d55d6adb1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting y against x, you'll observe a positive linear relationship:\n",
    "x = runif(50,0,50)\n",
    "y = x + rnorm(50,0,5)\n",
    "pearson_cor_coef = cor(x,y)\n",
    "list(\"cor\"=pearson_cor_coef,\"R^2\"=pearson_cor_coef^2)\n",
    "cor.test(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b48a5-777a-4188-84a8-c012ff7721ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "$r$ is 0.94 which means that the two variable are higly and positively correlated. There is a linear relationship between the sample. Is it this relationship significant also for the entire population?\n",
    "\n",
    "- $H_0$: $\\rho = 0$\n",
    "- $H_1$: $\\rho \\neq 0$\n",
    "\n",
    "p-value is much smaller that the significance level 0.05 therefore the null-hypotesis which state that there is not correlation is rejected. Consequentely, it could be valid the alternative hypotesis which stat that there is a significant linear relationship.  Our extremely low p-value means that there is a 0.00000000000000002% chance we are wrong in our decision to reject the null hypothesis.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afacdb83-6cb0-40f7-b040-7c42635834f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercize:</b> Perform linear correlation analysis on trees dataset for the tree variables (data=trees).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe39d96a-afcd-4659-916d-5e2dcda14ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=trees\n",
    "trees\n",
    "help(trees)\n",
    "#case 1 Y=Height and X=Girth\n",
    "#case 2 Y=Height and X=Volume\n",
    "#case 3 Y=Volume and X=Girth\n",
    "#case 4 Y=Volume and X=Height\n",
    "#case 5 Y=Girth and X=Height\n",
    "#case 6 Y=Girth and X=Volume\n",
    "\n",
    "x=trees$Girth\n",
    "y=trees$Height\n",
    "plot(y~x)\n",
    "pearson_cor_coef = cor(x,y)\n",
    "list(\"cor\"=pearson_cor_coef,\"R^2\"=pearson_cor_coef^2)\n",
    "\n",
    "x=trees$Volume\n",
    "y=trees$Height\n",
    "plot(y~x)\n",
    "pearson_cor_coef = cor(x,y)\n",
    "list(\"cor\"=pearson_cor_coef,\"R^2\"=pearson_cor_coef^2)\n",
    "\n",
    "x=trees$Girth\n",
    "y=trees$Volume\n",
    "plot(y~x)\n",
    "pearson_cor_coef = cor(x,y)\n",
    "list(\"cor\"=pearson_cor_coef,\"R^2\"=pearson_cor_coef^2)\n",
    "\n",
    "x=trees$Height\n",
    "y=trees$Volume\n",
    "plot(y~x)\n",
    "pearson_cor_coef = cor(x,y)\n",
    "list(\"cor\"=pearson_cor_coef,\"R^2\"=pearson_cor_coef^2)\n",
    "\n",
    "x=trees$Height\n",
    "y=trees$Girth\n",
    "plot(y~x)\n",
    "pearson_cor_coef = cor(x,y)\n",
    "list(\"cor\"=pearson_cor_coef,\"R^2\"=pearson_cor_coef^2)\n",
    "\n",
    "x=trees$Volume\n",
    "y=trees$Girth\n",
    "plot(y~x)\n",
    "pearson_cor_coef = cor(x,y)\n",
    "list(\"cor\"=pearson_cor_coef,\"R^2\"=pearson_cor_coef^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbad85e-2dec-42ac-b0d6-7679c198f4b4",
   "metadata": {},
   "source": [
    "Final Remarks: \n",
    " \n",
    "__Assumption of linear correlation:__ pearson correlation assume that the data samples are taken by a population normally distributed. If not we need to use a \"non-parametric test\" for correlation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0038f6e-a798-48b8-b455-b353ca6f8a83",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Linear Regression\n",
    "\n",
    "Dependent variable $Y$ has a __functional relation__ with the independent variable $X$ (one way relationship).\n",
    "$Y$ dependent by $X$ does not mean that we demonstrate a causality relationship ( $Y$ variation caused by $X$ variation) but only that there is some relationship.\n",
    "The main use of regression analysis is to __predict__ values of the dependent variable. \n",
    "Pratically, a linear regression analysis provide an equation for a line that describe the fucntional relationship between two variables and tests whether the statistics that describe this line are significantly different from zero.\n",
    "\n",
    "For a straight line:\n",
    "\n",
    "\n",
    "$$ Y_i=a+bX_i $$\n",
    "\n",
    "equation with $a$ -> Interception with $X=0$ and $b$ -> line slope\n",
    "\n",
    "Usually this straight line is a *\"best fit\" line* through a set of data points (the line that lies as close as possible to all the data points). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b18f34-6cd3-4f69-be7c-57eabcd9bb74",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Perform linear correlation and test the null-hypotesys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66799309-5c35-4673-b42d-19dcec83d72b",
   "metadata": {
    "tags": []
   },
   "source": [
    "The significance of a correlation can be tested using `cor.test()`, which also provides a 95% confidence interval on the correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b9221-58d5-439c-bb69-5f3743c7fe61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cor.test(trees$Volume,trees$Girth) #null-test hypotesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b83f6b-8e3d-4fbe-b201-f7b76d02cc13",
   "metadata": {},
   "source": [
    "$r$ = 0.967 high enough to indicate that there is a reasonably strong correlation between $X$ (Girth) and $Y$ (Volume) in this range\n",
    "\n",
    "Again we should ask if the linear relationship identified between two variables describing the observed sample is valid also in the population? The correlation coefficient deviates significantly different from zero? The null hypotesis is $\\rho=0$ (There is NO Linear relationship) which means that the non-linearity of the correlation is significant, the alternative hypotesis is $\\rho \\neq 0$ (There is Linear relationship) which means that the linearity of the correlation is significant.\n",
    "\n",
    "1. check if the null-hypotesis is retained or rejcted.\n",
    "\n",
    "p-values is lower than significance level of 0.05 therefore the null-hypotesis on correlation $\\rho=0$  is rejectd. \n",
    "\n",
    "2. chose the alternative hypotesis \n",
    "Rejecting the null-hypotesis means that there could be correlation significance. Overall p-value is low enough to suggest that the model has significant utility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d70cc-d141-4ff1-80ad-7865bae37023",
   "metadata": {},
   "source": [
    "### 2.2 Perform linear regression and test the null-hypotesys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbc396-8232-4d2b-9742-4e9c402874a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot(Volume~Girth,data=trees)\n",
    "m1 = lm(Volume~Girth,data=trees) #fitting linear model function\n",
    "abline(m1, col=\"red\",lwd=2) # add straiht line to a plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4f6126-d8a7-45a4-87b9-1f88b97ce179",
   "metadata": {},
   "source": [
    "Once obtained the regression line, we should ask ourself if it is statistically significant (testing the null-hypotesis).\n",
    "We need to test the $a$ and $b$ (interception and slope)\n",
    "\n",
    "- Slope testing $b$: one method is similar to the One-Way ANOVA. We don't test the sample extraction displacement form the mean but we test the sample tilting extraction from the not-tilted condition.\n",
    "\n",
    "$$F_{ratio} = \\frac{MS_{regression}}{ MS_{residual}}$$\n",
    "incrasing $F$ the probability p-value decrease (0.05)\n",
    "\n",
    "- Ineterception testing $a$:\n",
    "we  see the displacement of an extracted with the population.\n",
    "\n",
    "It is all implemented in the __linear model function__ `lm()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd71f3b-f223-4893-8134-e885f2779ea1",
   "metadata": {},
   "source": [
    "The significance of the slope and the interception of the regression line can be tested using `lm()`.\n",
    "\n",
    "Result table from a regression analysis is provided by the *summary(m1)*:\n",
    "\n",
    "|                                                        | Estimated Value | Std.Error | t-value              | p-value              |\n",
    "|--------------------------------------------------------|-----------------|-----------|----------------------|----------------------|\n",
    "| (Intercept) is the $a$                                 |                 |           | comparing $a$ to $0$ | comparing $a$ to $0$ |\n",
    "| Girth, the name of the Independent Variable is the $b$ |                 |           | comparing $b$ to $0$ | comparing $a$ to $0$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c817e2-dc2d-43ad-bde6-c41fa6a9bcee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1be8fa-14be-45aa-88db-12daa4e10db0",
   "metadata": {},
   "source": [
    "A slope of 5.06 means that, for an increase of one unit in the Girth (that is, an increase of 1 inch), the Volume of the trees increases, on average, by 5.06 units.\n",
    "\n",
    "Overall p-value is low enough to suggest that the model has significant utility, and both terms (the intercept $b$ and the coefficient of Girth $a$) are significantly different from zero. This means that we are rejecting the null-hypotesis of absence of regression significance and accepting the anternative hypotesis. \n",
    "\n",
    "The $R^2$ value of 0.9353 is high enough to indicate that there is a reasonably strong correlation between $X$ (Girth) and $Y$ (Volume) in this range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dbc274-4524-49de-84ba-64a1a66a18df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#residuals from least squared minimization for line best fit.\n",
    "\n",
    "#Model residuals can be readily accessed using the `residuals()` function:\n",
    "hist(residuals(m1),breaks=10,col=\"light grey\")\n",
    "\n",
    "\n",
    "library(ggplot2)\n",
    "ggplot(data=trees, aes(m1$residuals)) +\n",
    "geom_histogram(binwidth = 1, color = \"black\", fill = \"purple4\") +\n",
    "theme(panel.background = element_rect(fill = \"white\"),\n",
    "axis.line.x=element_line(),\n",
    "axis.line.y=element_line()) +\n",
    "ggtitle(\"Histogram for Model Residuals\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6500488-503f-4409-b0f4-57a77848ef38",
   "metadata": {},
   "source": [
    "### 2.3 Predicting a value of y from a value of x\n",
    "\n",
    "We can use the regression line to make predictions on a certain given variable. Notice that it is dangerous to make predictions beyond the measured range of X.\n",
    "\n",
    "example: for a `Girth` value of 15.6 inch, which could be the predicted `Volume` of my tree specie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b0499e-4c3f-41dc-b376-0e9c7fa4252f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict(m1, data.frame(Girth = 15.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fec169-d4db-4fdf-aa13-729de639a963",
   "metadata": {},
   "outputs": [],
   "source": [
    "Girth <- seq(9,21, by=0.5) ## make a girth vector\n",
    "pred_grid <- expand.grid(Girth = Girth)\n",
    "## make a grid using the vectors\n",
    "pred_grid$Volume <-predict(m1, new = pred_grid)\n",
    "#plot\n",
    "fit_2_sp <- plot(pred_grid$Girth, pred_grid$Volume, pch = 1, ylab = \"Volume (ft3)\", xlab = \"Girth (in)\", main=\"prediction of several Volume for a set of Girth measures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d731353e-e063-44cc-9b33-bef6ea5afe67",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Be carefull!</b> Are we shure that linear regression is a good model for our data? in other words, are we respecting the assumptions?</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c551efb-d49b-4bd3-bee9-024e0f1138f0",
   "metadata": {},
   "source": [
    "### 2.4 Assessing the validity of linear model\n",
    "Diagnostic plots for the model can reveal whether or not modelling assumptions are reasonable.\n",
    "The conditions of application for using simple linear regrassion are:\n",
    "\n",
    "1. Linearity of the relationships between the dependent and independent variables\n",
    "2. Independence of the observations (how we have measured/acquired the samples)\n",
    "3. Normality of the residuals (observe Q-Q plot)\n",
    "4. Homoscedasticity of the residuals (observe Residuals vs Fitted)\n",
    "5. No influential points (outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e691c-fcd9-4dfa-bf44-afb5fb663e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot the result m1 of the linear model:\n",
    "plot(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6dfc4-ae87-4a4e-aba2-7a43b19bcdfd",
   "metadata": {},
   "source": [
    "__Conclusions:__ In this case, there is visual evidence to suggest that the assumptions are not satisfied - note in particular the trend observed in the plot of residuals vs fitted values. The `summary(m1)` show a misleading results, as we know that a linear model is inappropriate in this case. Indeed, the linear model summary does not check whether the underlying model assumptions are satisfied. By observing strong patterns in the diagnostic plots, we can see that the modelling assumptions are not satisified in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7beb3d-0eed-4abd-84ae-b640cefca624",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Use psych library to show:\n",
    "\n",
    "    1. Correlation coefficient (r) - The strength of the relationship.\n",
    "    2. Histogram with kernel density estimation and rug plot.\n",
    "    3. Scatter plot with fitted line and ellipses to display the strength of the relationship.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1aa0f4-624d-4322-8e0a-8dd9ece60293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(psych)\n",
    "\n",
    "pairs.panels(trees, scale=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45189dd2-5fb7-441d-8c60-64a0d81d18e9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercize:</b> Perform all section 2 analysis considering the Hight independent variable instead of Girth for the tree dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed27a4-74ce-45f0-b966-100d187b232b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercize:</b> Perform linear correlation and linear regression analysis on the following dataset and observe test results as well as the respect of the hypotesis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffe9d59-b0db-4284-933f-37ae6e04ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = seq(0,1.5*pi,0.2) #dependent variable\n",
    "y=sin(x) # Independent variable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
